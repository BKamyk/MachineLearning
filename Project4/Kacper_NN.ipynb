{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Define activation functions and their derivatives\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    m = targets.shape[0]\n",
    "    return -np.sum(targets * np.log(predictions + 1e-9)) / m\n",
    "\n",
    "# Simulate Data (for testing the NN architecture while ensuring smooth execution)\n",
    "np.random.seed(42)\n",
    "num_samples = 100  # Number of images (mocked data)\n",
    "image_size = (64, 64)  # Resized image dimensions\n",
    "num_classes = 10  # Number of target classes\n",
    "\n",
    "# Create mock training data\n",
    "mock_train_data = np.random.rand(num_samples, image_size[0] * image_size[1])  # Random image data\n",
    "mock_train_labels = np.eye(num_classes)[np.random.choice(num_classes, num_samples)]  # One-hot encoded labels\n",
    "\n",
    "# Initialize neural network parameters\n",
    "input_size = image_size[0] * image_size[1]  # Input dimension\n",
    "hidden_layer_size = 128  # Hidden layer size\n",
    "output_size = num_classes  # Number of classes (output layer)\n",
    "\n",
    "weights_input_hidden = np.random.rand(input_size, hidden_layer_size) * 0.01\n",
    "weights_hidden_output = np.random.rand(hidden_layer_size, output_size) * 0.01\n",
    "bias_hidden = np.zeros((1, hidden_layer_size))\n",
    "bias_output = np.zeros((1, output_size))\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input = np.dot(mock_train_data, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    predictions = softmax(output_layer_input)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = cross_entropy_loss(predictions, mock_train_labels)\n",
    "    \n",
    "    # Backward propagation\n",
    "    output_error = predictions - mock_train_labels  # Gradient of loss w.r.t. output layer\n",
    "    hidden_error = np.dot(output_error, weights_hidden_output.T) * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "    weights_input_hidden -= learning_rate * np.dot(mock_train_data.T, hidden_error)\n",
    "    bias_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "    bias_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "    # Log progress\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs} - Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Training complete with mock data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images from the second training folder\n",
    "train_data_2, train_targets_2 = preprocess_images(\"training set part 2\", labels_dict)\n",
    "\n",
    "# Continue training loop with the second folder data\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input = np.dot(train_data_2, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    predictions = np.exp(output_layer_input - np.max(output_layer_input, axis=1, keepdims=True))\n",
    "    predictions /= np.sum(predictions, axis=1, keepdims=True)  # Softmax activation\n",
    "\n",
    "    # Compute loss\n",
    "    loss = -np.sum(train_targets_2 * np.log(predictions + 1e-9)) / train_targets_2.shape[0]\n",
    "    \n",
    "    # Backward propagation\n",
    "    output_error = predictions - train_targets_2  # Gradient of loss w.r.t. output layer\n",
    "    hidden_error = np.dot(output_error, weights_hidden_output.T) * hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "    weights_input_hidden -= learning_rate * np.dot(train_data_2.T, hidden_error)\n",
    "    bias_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "    bias_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "    # Log progress\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs} - Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Training complete with the second folder data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CSV file\n",
    "labels_path = \"Train Images Labeling.csv\"  # Path to your CSV file\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Convert to dictionary: {ImageId: ClassName}\n",
    "labels_dict = dict(zip(labels_df[\"ImageId\"], labels_df[\"ClassName\"]))\n",
    "\n",
    "# Map class names to numerical labels for one-hot encoding\n",
    "unique_classes = sorted(set(labels_df[\"ClassName\"]))\n",
    "class_to_index = {class_name: i for i, class_name in enumerate(unique_classes)}\n",
    "\n",
    "# Update labels_dict to use numerical labels\n",
    "labels_dict = {key: class_to_index[value] for key, value in labels_dict.items()}\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_images(folder_path, labels_dict, image_size=(64, 64)):\n",
    "    data = []\n",
    "    targets = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            # Load and resize image\n",
    "            img_path = os.path.join(folder_path, file_name)\n",
    "            img = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "            img_resized = img.resize(image_size)\n",
    "            img_array = np.array(img_resized).flatten() / 255.0  # Normalize pixel values\n",
    "            \n",
    "            # Append to data and get label\n",
    "            data.append(img_array)\n",
    "            if file_name in labels_dict:\n",
    "                label = labels_dict[file_name]\n",
    "                one_hot_label = np.eye(len(unique_classes))[label]\n",
    "                targets.append(one_hot_label)\n",
    "    \n",
    "    return np.array(data), np.array(targets)\n",
    "\n",
    "# Path to your training folders\n",
    "train_folder_1 = \"Part 1 - training set\"\n",
    "train_folder_2 = \"training set part 2\"\n",
    "\n",
    "# Process training images\n",
    "train_data_1, train_targets_1 = preprocess_images(train_folder_1, labels_dict)\n",
    "train_data_2, train_targets_2 = preprocess_images(train_folder_2, labels_dict)\n",
    "\n",
    "# Combine both training parts\n",
    "train_data = np.vstack((train_data_1, train_data_2))\n",
    "train_targets = np.vstack((train_targets_1, train_targets_2))\n",
    "\n",
    "# Initialize neural network parameters\n",
    "image_size = (64, 64)  # Resized image dimensions\n",
    "input_size = image_size[0] * image_size[1]  # Input dimension\n",
    "hidden_layer_size = 128  # Hidden layer size\n",
    "output_size = len(unique_classes)  # Number of classes (output layer)\n",
    "\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.rand(input_size, hidden_layer_size) * 0.01\n",
    "weights_hidden_output = np.random.rand(hidden_layer_size, output_size) * 0.01\n",
    "bias_hidden = np.zeros((1, hidden_layer_size))\n",
    "bias_output = np.zeros((1, output_size))\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input = np.dot(train_data, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    predictions = np.exp(output_layer_input - np.max(output_layer_input, axis=1, keepdims=True))\n",
    "    predictions /= np.sum(predictions, axis=1, keepdims=True)  # Softmax activation\n",
    "\n",
    "    # Compute loss\n",
    "    loss = -np.sum(train_targets * np.log(predictions + 1e-9)) / train_targets.shape[0]\n",
    "    \n",
    "    # Backward propagation\n",
    "    output_error = predictions - train_targets  # Gradient of loss w.r.t. output layer\n",
    "    hidden_error = np.dot(output_error, weights_hidden_output.T) * hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "    weights_input_hidden -= learning_rate * np.dot(train_data.T, hidden_error)\n",
    "    bias_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "    bias_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "    # Log progress\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs} - Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Test set processing\n",
    "test_folder = \"Test_set\"\n",
    "test_data, _ = preprocess_images(test_folder, {}, image_size=image_size)  # No labels for test set\n",
    "\n",
    "# Test set predictions\n",
    "hidden_layer_input = np.dot(test_data, weights_input_hidden) + bias_hidden\n",
    "hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))\n",
    "output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "test_predictions = np.exp(output_layer_input - np.max(output_layer_input, axis=1, keepdims=True))\n",
    "test_predictions /= np.sum(test_predictions, axis=1, keepdims=True)\n",
    "\n",
    "# Output predicted classes for the test set\n",
    "predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"Train Images Labeling.csv\"\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Print column names\n",
    "print(labels_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
